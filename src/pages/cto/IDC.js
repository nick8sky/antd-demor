import React, { Component } from 'react';

class IDC extends Component {
    render() {
        return (
            <div>
                <h2>异地多活IDC机房架构</h2>
                <p>Internet Data Center互联网数据中心，简称IDC数据中心。</p>
                <p>单机房一旦死机，断电、维护根本无法挽回整个数据，想离线读取等都不行。当一个机房不可用，所有的业务就都不可用。系统 要求业务离用户最近，南方的用户连南方的机房，北方的用户连北方的机房，国外的用户连国外的机房。大陆的网络和国外的网络有一定的隔离性，如果没有做多机房的连通性，数据的传输和实时性就会有问题。</p>
                <p>&nbsp;</p>
                <p>一个支付系统：</p>
                <p><img src={require('../../img/7497cfece9ffdfacadf67f646a24dc1a7287510f.png')}  style={{height:"40%",width:"40%"}}/></p>
                <ol>
                    <li>通过域名做负载均衡，将请求路由到最近的可用服务的机房</li>
                    <li>服务全部机房内自治，不进行跨机房访问</li>
                    <li>机房1的DB（mysql）仅有一个，机房2跨机房访问机房1的DB进行读写</li>

                </ol>
                <p>整个架构看起来是可行的，并且当时也是有在生产环境使用。但是不难看出，机房2的服务，在响应时间上肯定要比机房1更慢。因为跨机房访问数据库带来了一定的网络延时，在最正常的情况下，通过当时购买的专线，可以控制在数十ms以内。</p>
                <p><strong>当机房1故障时，通过dns切换（据说可以智能切换，不过我们当时并没有实施）关闭机房1的请求，然后将机房2的数据库从slave升级为master，就可以完成整个容灾过程。看起来并不是全自动的，但至少比服务长时间瘫痪等待机房修复要好。而且，dns切换以及db切换，都可以通过自动的方式来实现。</strong></p>
                <p>上面的方案实现简单，对于一般的业务也够用了。但是，存在以下几个问题。而这几个问题，也是异地容灾跨不过的坎。</p>
                <ol>
                    <li>机房间延时。不管是机房2访问机房1的DB，还是DB之间的主从同步，都进行了跨机房的网络请求，其延时是难以避免的。</li>
                    <li>专线网络需要花钱，而且不便宜。严格来讲，你拉一条专线网络，这也是一个单点服务。如果要做到专线网络容灾，价格应该至少要翻番吧。</li>
                    <li>数据同步。对于实时性要求不高的业务，比如微信发朋友圈，可以允许延时。但对于支付（账号余额）这种数据来讲，必须是强一致性的。如果机房1挂了，机房2备份库的数据还是一份脏数据，那必然会带来重大的损失。所以，这种数据同步方案，对于强一致性要求的数据，是不可接受的。对于强一致性的数据，只有通过人为修复确保都更新到位后，才能恢复服务。也就是在此期间，其实服务也处于不可用状态。</li>

                </ol>
                <p>通过以上分析，我们不难看出，1.2两个缺点，可以勉强花钱解决，但是对于3，花钱也解决不了。那么，对于强一致性要求的数据，我们如何来做容灾呢？</p>
                <ol>
                    <li>机房1、机房2实现双主（Master-Master）的数据库架构。两个数据库分别置于机房1和机房2，实现读写。master之间通过mysql的内部实现，进行数据同步。这个方案其实跟之前的方案区别不大，只是减少了服务去访问数据库的网络延时，属于一个伪数据强一致性方案。而且双主很依赖网络延时进行数据同步，同时容易出现脑裂现象，个人不推荐使用。</li>
                    <li> 通过业务层来实现分布式事务，以此来确保两个机房数据的强一致性。两个数据库分别置于两个机房中，通过业务程序来实现分布式事务，也就是通过业务层来确保数据库1和数据库2都更新成功，才视为更新成功。这样确实可以保证数据库1和数据库2的数据强一致性。但是增加了系统的实现复杂度，也增强了对开发人员能力的要求。另外，分布式事务会增加业务处理时长以及失败率，如果单机房故障一年都仅有几个小时，这种分布式的代价是否值得呢？</li>
                    <li>将服务状态化。<strong>对用户进行分区</strong>，将用户请求固定路由到机房1或机房2。如此一来，两个机房不会对同一份数据进行更新，也就避免了数据强一致性的要求。同时，这两个数据库之间，仍然通过主备进行数据备份。当其中一个机房故障时，通过人为修复该机房同步到另外一个机房的数据后，再恢复机房1中的服务。对比在上家公司已实现的方案，这种方案有两个优点：减小了跨机房访问数据库的延时；减小了受灾用户群体。个人觉得该方案不错，但是如何在dns解析域名时进行状态化呢？如果又引入中间件，那不是又单点了吗？</li>

                </ol>
                <p>&nbsp;</p>
                <p>阿里巴巴“异地多活”技术？</p>
                <p><a href='http://servers.pconline.com.cn/721/7215376.html' target='_blank' >http://servers.pconline.com.cn/721/7215376.html</a></p>
                <p>异地多活最重要的目的除了灾备之外，更重要的点是追求持续可用，整个支付交易的体量对于用户来讲是持续可用。</p>
                <p>&nbsp;</p>
                <p>业界最重要的很多人都知道，最主流的灾备技术是两地三中心，数据中心A和数据中心B在同城作为生产级的机房，当用户访问的时候随机访问到数据中心A或B。之所以随便访问，因为A和B会同步做数据复制，所以两边的数据是完全一样的。但是因为是同步复制的，所以只能在同城去做两个数据中心，否则太远的话同步复制的延时会太长。在两地三中心的概念里，一定会要求这两个生产级的数据中心是必须在同一个城市，或者在距离很近的另外一个城市也可以，但是距离是有要求的。</p>
                <p>异地备份数据中心通过异步复制去走，但正常情况下异地备份的数据中心是不起用的，也不对外服务，所以用户不会访问到异地的点。原因是因为数据从生产级数据中心到异地的节点是异步去复制，所以整个有延时。这是整个业界目前用的比较多的业界。</p>
                <p>&nbsp;</p>
                <p>两地三中心对于阿里来讲看到的问题，最重要的问题：</p>
                <p>　　1、这个模式不一定Work。大家可能都看到某些新闻里讲过，比如说某些地方用了两地三中心之后，当一地的数据中心出问题的时候，是不敢流量切往异地的备份数据中心，原因是异地的备份数据中心是冷的，平时是没有用户流量进去的。如果要把流量切到那边起来之后，其实没有人有多强的信心能够保障起用以后是可以正常服务的，毕竟平时都是冷的。因为是冷的，就意味着整个起用的过程需要时间，不可能说起用就起用，一定会有时间周期。这是两地三中心的最大问题，看起来模式是很安全的，也是可用的，但是事实上不一定是这样。</p>
                <p>　　2、异地备份中心因为不对外提供服务，所以整个资源会处于浪费状态，成本比较高及</p>
                <p>　　3、对于阿里的规模来讲有一个很大的问题，在两地三中心中，数据一定是单点去写。其实数据只在一个地方去写，这个时候如果整个压力比较高，比如像“双十一”的场景中压力非常高的情况下，就意味着在两地三中心的情况下所有的数据还是写上的单个点，对于存储成本压力会不断增加。比如去年8万、今年14万意味着每年压力都在增加，这时候数据库整个伸缩和外层业务的伸缩都面临着更大挑战。</p>
                <p>　　对于我们来讲这三个问题是比较明显的。</p>
                <p>　　阿里在整个高可用上也经历过了一段时间，主要是做了三个步骤。第一个是做了同城的双活，第二个做了异地只读及冷备，第三个是做了异地多活，经历了三代体系的演进才走到了今天。</p>
                <p>&nbsp;</p>
                <p>双活是觉得备用数据中心只做备份太浪费了，所以让主备两个数据中心都同时承担用户的业务，此时，主备两个数据中心互为备份，并且进行实时备份。一般来说，主数据中心的负载可能会多一些，比如分担60~70%的业务，备数据中心只分担40%~30%的业务。</p>
                <p>阿里做同城双活做了挺长一段时间才真正做成功，因为双活其实也是一样的，如果真正做到就意味着同城任何一个机房出问题都可以全量切换到另外一个机房，如果没有经过很多次真正切换的话，是没有人敢说是一定能成功的。所以阿里在那一年也是花了时间演练了非常多次，才真正能做到。</p>
                <p>&nbsp;</p>
                <p>在完成同城双活的改造之后开始尝试异地，同城毕竟还是有很多因素的风险，所以去尝试能不能走到异地远的城市。最早尝试的是只读业务和冷备，把阿里的某些业务部署到另外一个城市去，开始只是冷备用，冷备后来完全没有办法接受，因为阿里的规模一年比一年大，冷备的成本越来越高，这个钱不值得付出。另外是冷备不Work，出状况下不敢迁到异地去。</p>
                <p>&nbsp;</p>
                <p>　　后来在这上面做了一点改进，所以决定把只读业务在异地起用，比如说像搜索等等算只读。但是发现对于阿里业务来讲，只读业务很难抽象，因为只能服务只读业务，如果有写就不能做。如果写的话，就意味着写到另外一个城市，这个延时接受不了，后来只读也觉得没有太大意义。</p>
                <p>　　当阿里完成同城双活以及异地只读、冷备尝试以后，阿里的阶段也还只是两地三中心。或可以认为是两地三中心稍微的升级版本，因为只读业务有部分的开放，有一部分的进步，但不是最理想的状态。</p>
                <p>　　阿里决定开始做异地多活，对于我们来讲，我们要去做到异地多活，要的目标是：</p>
                <p>　　1、需要多个跨地域的数据中心。异地多活是跨地域的，而且距离一定要做到1000公里以上的范围，其实在中国范围内全国城市都可以去布了。</p>
                <p>　　2、每个数据中心都要承担用户的读写流量。如果只是备或只读业务来讲，作用不是很大。</p>
                <p>　　3、多点写。因为每个数据中心去承担用户读写流量的话，如果读或写集中到全国一个点的话，整个延迟是没有办法承受的。</p>
                <p>　　4、任意一个数据中心出问题的时候，其他中心都可以分钟级去接管用户的流量。</p>
                <p>　　这个是阿里在做异地多活项目的时候，希望在这四点上都能够做到，然后也只有这样的情况下才认为是一个异地多活的业务。</p>
                <p>　　异地多活对于我们来讲，其实很多人都可以看到异地多活最大的挑战是什么？</p>
                <p>　　1、距离。看起来距离没有什么，比如说1000公里以上也就是30毫秒的网络延迟，来回一次是30毫秒左右。30毫秒对于用户来讲，如果只是给你增加30毫秒，用户其实没有感受。但是当你打开一个淘宝页面的时候，事实上当你在商品页面看到一个商品点立刻购买的时候，页面的背后大概有100多次以上的后端交互，如果100多次全部跨地域完成的话，就意味着页面的响应时间将增加3秒。如果增加3秒，用户绝对会有明显感受。因为对于阿里来讲，很多页面就出不来了，3秒已经超时了。对于我们来讲，这第一点是直接带来用户体验的不可用。</p>
                <p>	距离成本，当系统响应时间增高的时候，意味着每年“双十一”增加的QPS将付出更大的成本，因为吞吐量在下降，这个时候的成本也是很难接受的。<strong>距离带来的延时问题是最大的问题</strong>。</p>
                <p>　　2、多点读写是解决距离的问题，但是多点写了就会带来第二个更复杂的问题， <strong>多点写带来的数据正确性问题</strong>，这对我们来讲是最致命的。多点写，比如说出现这一次访问在A数据中心写的数据，然后再访问的时候到B数据中心又写了一条数据，两条数据如果合不到一起的话。对于大家最直观的感受是有可能买了一个东西付了钱，而看到的是没付钱。或者夸张点已经收到商品了，压根就没有看到购买记录。对于阿里来讲，这是最大的一个问题。</p>
                <p>　对于我们来讲，在多点写的情况下最大的挑战是怎么保证用户写入的数据一定是在正确的地方，另外看到的一定是一致的，这是整个异地多活中最大的挑战。</p>
                <p>　　针对这两个个问题，对于延时的问题来讲，<strong>其实延长时的问题意味着最好的解决方案是什么呢？如果这一次访问页面的整个操作全部在当前机房内完成的，自然就不存在延时问题，因为没有跨出去。</strong></p>
                <p>&nbsp;</p>
                <p>　   针对第二个问题，异地。在全国部署的时候，意味着是不是要把整个业务全部全国部署，因为这有成本因素。大家知道阿里的业务非常庞杂，其实没有必要把所有的业务都在全国部署，因为不是所有的业务都有足够的量。</p>
                <p>　　因为不是整个业务全国部署，所以决定起另外一个名字叫单元化。意味着我是把业务划成了各种各样的单元，比如有交易的单元，这个单元是完成交易业务，所以在内部代号是单元化项目。</p>
                <p>　　为了解决延时问题，能在一个机房内完成就不存在延时问题。另外一个核心思想是单元封闭，需要让单元内的应用访问和数据的读写操作全部处于封闭状态，这就是最完美的状况。如果能做到这样，其实在全国任意城市部署都不会有问题。</p>
                <p>&nbsp;</p>
                <p>　　开始多点写以后，怎么去保障整个数据写入的正确性以及一致性。 </p>
                <p>	对于异地多活来讲，还有数据一致性中很大的挑战会出现在流量切换的动作中，比如说AB两个数据中心，A开始是承担20%的流量，B承担80%的流量。当把流量从A切到B的时候，有可能出现切换过程中A还在写，而读到B了，有可能看到出现的数据是不一致的。怎么保证在整个流量切换过程中数据是绝对一致的，我们也做了很多的东西。</p>
                <p>　　在异地整个数据中心还有另外一个非常重要的核心技术产品，就是我们需要一个数据同步的东西。因为大家知道阿里现在除了OB以外，很重要的一块是MySQL，MySQL自己的主备是没有办法满足要求，在异地做到延时是没有办法满足的，我们决定做了自研的数据同步产品。在2015年“双十一”中，所有数据同步控制在1秒以内，1秒以内是可以接受的。</p>
                <p>　　阿里为了做到整个异地多活，其实自己也折腾了很多年。这个项目在阿里内部总共花了三年的时间，自己在最近的一封总结邮件中也写到，经历了三年的磨炼，我们终于把异地多活变成了阿里电商架构级的能力，意味着在整个架构中具备异地多活的能力，在以前是不具备的。</p>
                <p>　　我们为了整个过程中是比较平滑的，因为不能对业务产生太大影响，所以分了三年的时间去完成。在2013年首先采用的是在同城起用了两个单元双活，真正意义的双活，因为那两个单元都是写自己的数据库的，两个单元都是双写。</p>
                <p>	之所以在2013年选择同一个城市，是因为我们担心单元化改造没有完成的情况下如果走向异地，可能会因为延时问题导致页面打不开，那个问题是非常严重的，所以决定先在同城做。同城的话，及时没有改造好，跨出去了也没有关系，因为还在同城，延时是可控的。</p>
                <p>　　在2014年觉得可以往前更进一步，选择了距离更近的城市，其实还是有延时。如果没有做过单元化改造业务部署到异地的时候，页面会超时，有些页面打不开。但是因为单元化在背后就没有太大问题，在2014年成功在两个相距有一定距离的城市起用了异地双活，在去年“双十一”中两个城市分别承担了50%的用户流量，有些用户会访问一个城市，有些用户访问另外一个城市，当下单的时候会下在同一个城市里面。</p>
                <p>&nbsp;</p>
                <p>	在今年单元化可以宣告能力基本成熟的阶段，所以在今年开始起用了距离在1000公里以上的另外一个数据中心，然后今年数据中心是多点部署。从2015年从2个变成3个或4个以后，对于我们来讲的另外一点是因为距离增加到了1000公里以上，基本上意味着阿里整个电商以及支付是可以在全国任意一个城市去部署，并且可以部署多个，意味着以后的“双十一”整个扩充能力是会变得很容易。</p>
                <p>　　对于我们来讲，当阿里整个架构能力进一步提升到了异地多活时代以后，对于我们来讲带来了两个好处：</p>
                <p>　　第一、有极强的水平伸缩能力。以前做“双十一”的时候，都必须去算，比如去年8万笔，今年14万笔的时候，必须要算增加的6万。还有因为每年业务模式的变化需要算每个应用加多少机器。但是在单元的情况下，一组单元就是多大的能力，然后只要按照单元扩充就结束了。假设一个单元可以做到2万笔，其实14万笔对于我们来讲是建设7个单元就结束了，整个伸缩能力会比以前强大非常多。而且每个单元都是写自己的数据库和存储层，包括cache全部写自己的，这个时候伸缩规模是可控的，不像以前不断加，数据库有可能抗不住。在抗不住的时候可能会做分布等等，但其实也是比较复杂的，现在我们改变了伸缩力度的模式。</p>
                <p>　　第二、异地多活怎么去应对故障。比如在阿里内部会按照这样的等级去划分所有业务能够支持故障应对能力，比如说单实例出故障在多久能恢复，或者单机房或单城市或全局的服务，比如DNS等等，我们会按照这个对每个业务，然后就知道每个业务当出现故障时整个应对能力是怎样的。</p>
                <p>　　这个是今年“双十一”的图，背后有一个淘宝的异地多活，在这张图上可以看到有4个点的流量。如果大家去翻去年的“双十一”，发现去年是2个点，然后今年变成了4个点。下面的比例是我们随时都可以变化的，所以大家不用太在意。其实淘宝的异地多活或者整个阿里的交易额支付其实经常切，比如在昨天就切了好几次流量。其实我们整个是可以不断去做的。支付宝和淘宝稍微有点不同，支付宝今年起用了两个，分别是华南和华东，分别有不同比率的流量。</p>
                <p>　　。</p>
                <p>	阿里自己也经历了三年的磨炼，阿里云很大的价值是可以让你在更简单的情况下获取到更强大的能力。比如阿里云的产品中像前段时间开放的DTS，内部做多个数据中心之间数据同步的产品。像下面的EDAS、DRDS、ONS是内部的中间件产品，在做整个异地多活过程中所有中间件都需要改造，否则没有办法做异地多活。这些开放的产品，自然在内部具备了异地多活的能力。所以当外部用户去用的时候，当演进到这一步会比阿里巴巴简单很多，因为阿里逐渐往外开放。</p>
                <hr />
                <p> 比如说假设我们需要做一个“用户子系统”，这个子系统负责“注册”、“登录”、“用户信息”三个业务。为了支持海量用户，我们设计了一个“用户分区”的架构，即：正常情况下用户属于某个主分区，每个分区都有其它数据的备份，用户用邮箱或者手机号注册，路由层拿到邮箱或者手机号后，通过hash计算属于哪个中心，然后请求对应的业务中心。基本的架构如下： </p>
                {/*<p><img src={require('../../img/9dd2bbb38e092fe164d082aa2bca252646281290.gif')}  style={{height:"80%",width:"80%"}}/></p>*/}
                <p><img src="http://i4.bvimg.com/633340/4b49284f5c35537a.gif"  style={{height:"80%",width:"80%"}}/></p>

                    <p>考虑这样一个系统，如果3个业务要同时实现异地多活，我们会发现如下一些难以解决的问题：</p>
                <p>【注册】</p>
                <p>A中心注册了用户，数据还未同步到B中心，此时A中心宕机，为了支持注册业务多活，那我们可以挑选B中心让用户去重新注册。看起来很容易就支持多活了，但仔细思考一下会发现这样做会有问题：一个手机号只能注册一个账号，A中心的数据没有同步过来，B中心无法判断这个手机号是否重复，如果B中心让用户注册，后来A中心恢复了，发现数据有冲突，怎么解决？实际上是无法解决的，因为注册账号不能说挑选最后一个生效；而如果B中心不支持本来属于A中心的业务进行注册，注册业务的双活又成了空谈。</p>
                <p> 有的朋友可能会说：那我修改业务规则，允许一个手机号注册多个账号不就可以了么？</p>
                <p>这样做是不可行的，类似一个手机号只能注册一个账号这种规则，是核心业务规则，修改核心业务规则的代价非常大，几乎所有的业务都要重新设计，为了架构设计去改变业务规则，而且是这么核心的业务规则是得不偿失的。</p>
                <p> 【用户信息】</p>
                <p>用户信息的修改和注册有类似的问题，即：A、B两个中心在异常的情况下都修改了用户信息，如何处理冲突？</p>
                <p>由于用户信息并没有账号那么关键，一种简单的处理方式是按照时间合并，即：最后修改的生效。业务逻辑上没问题，但实际操作也有一个很关键的坑：怎么保证多个中心所有机器时间绝对一致？在异地多中心的网络下，这个是无法保证的，即使有时间同步也无法完全保证，只要两个中心的时间误差超过1s，数据就可能出现混乱，即：先修改的反而生效。</p>
                <p> 还有一种方式是生成全局唯一递增ID，这个方案的成本很高，因为这个全局唯一递增ID的系统本身又要考虑异地多活，同样涉及数据一致性和冲突的问题。</p>
                <p> 综合上面的简单分析，我们可以发现，如果“注册”“登录”、“用户信息”全部都要支持异地多活的话，实际上是挺难的，有的问题甚至是无解的。那这种情况下我们应该如何考虑“异地多活”的方案设计呢？答案其实很简单：优先实现核心业务的异地多活方案！</p>
                <p> 对于我们的这个模拟案例来说，“登录”才是最核心的业务，“注册”和“用户信息”虽然也是主要业务，但并不一定要实现异地多活。主要原因在于业务影响。对于一个日活1000万的业务来说，每天注册用户可能是几万，修改用户信息的可能还不到1万，但登录用户是1000万，很明显我们应该保证登录的异地多活。对于新用户来说，注册不了影响并不很明显，因为他还没有真正开始业务；用户信息修改也类似，用户暂时修改不了用户信息，对于其业务不会有很大影响，而如果有几百万用户登录不了，就相当于几百万用户无法使用业务，对业务的影响就非常大了：公司的客服热线很快就被打爆了，微博微信上到处都在传业务宕机，论坛里面到处是在骂娘的用户，那就是互联网大事件了！</p>
                <p> 而登录实现“异地多活”恰恰是最简单的，因为每个中心都有所有用户的账号和密码信息，用户在哪个中心都可以登录。用户在A中心登录，A中心宕机后，用户到B中心重新登录即可。</p>
                <p> 有的朋友可能会问，如果某个用户在A中心修改了密码，此时数据还没有同步到B中心，用户到B中心登录是无法登录的，这个怎么处理？这个问题其实就涉及另外一个思维误区了，我们稍后再谈。</p>
                <p>&nbsp;</p>
                <p>实时一致性</p>
                <p><strong>异地多活本质上是通过异地的数据冗余，来保证在极端异常的情况下业务也能够正常提供给用户，因此数据同步是异地多活设计方案的核心</strong>，但我们大部分人在考虑数据同步方案的时候，也会不知不觉的陷入完美主义误区：我要所有数据都实时同步！</p>
                <p> 数据冗余就要将数据从A地同步到B地，从业务的角度来看是越快越好，最好和本地机房一样的速度最好，但让人头疼的问题正在这里：异地多活理论上就不可能很快，因为这是物理定律决定的，即：光速真空传播是每秒30万公里，在光纤中传输的速度大约是每秒20万公里，再加上传输中的各种网络设备的处理，实际还远远达不到光速的速度。</p>
                <p> 除了距离上的限制外，中间传输各种不可控的因素也非常多，例如挖掘机把光纤挖断，中美海底电缆被拖船扯断、骨干网故障等，这些故障是第三方维护，我们根本无能为力也无法预知。例如广州机房到北京机房，正常情况下RTT大约是50ms左右，遇到网络波动之类的情况，RTT可能飙升到500ms甚至1s，更不用说经常发生的线路丢包问题，那延迟可能就是几秒几十秒了。</p>
                <p>因此异地多活方案面临一个无法彻底解决的矛盾：业务上要求数据快速同步，物理上正好做不到数据快速同步，因此所有数据都实时同步，实际上是一个无法达到的目标。</p>
                <p> 既然是无法彻底解决的矛盾，那就只能想办法尽量减少影响。有几种方法可以参考：</p>
                <ol>
                    <li>尽量减少异地多活机房的距离，搭建高速网络；</li>
                    <li>尽量减少数据同步；</li>
                    <li>保证最终一致性，不保证实时一致性；</li>

                </ol>
                <p> </p>
                <p>【减少距离：同城多中心】</p>
                <p>为了减少两个业务中心的距离，选择在同一个城市不同的区搭建机房，机房间通过高速网络连通，例如在苏州的姑苏区和吴江区各搭建一个机房，两个机房间采用高速光纤网络连通，能够达到近似在一个机房的性能。</p>
                <p>这个方案的优势在于对业务几乎没有影响，业务可以无缝的切换到同城多中心方案；缺点就是无法应对例如苏州全城被水淹，或者苏州全城停电这种极端情况。所以即使采用这种方案，也还必须有一个其它城市的业务中心作为备份，最终的方案同样还是要考虑远距离的数据传输问题，例如在杭州配一套机房。 </p>
                <p>【减少数据同步】</p>
                <p>另外一种方式就是减少需要同步的数据。简单来说就是不重要的数据不要同步，同步后没用的数据不同步。</p>
                <p>以前面的“用户子系统”为例，用户登录所产生的token或者session信息，数据量很大，但其实并不需要同步到其它业务中心，因为这些数据丢失后重新登录就可以了。
                    有的朋友会问：这些数据丢失后要求用户重新登录，影响用户体验的呀！
                    确实如此，毕竟需要用户重新输入账户和密码信息，或者至少要弹出登录界面让用户点击一次，但相比为了同步所有数据带来的代价，这个影响完全可以接受，其实这个问题也涉及了一个异地多活设计的典型思维误区，后面我们会详细讲到。 </p>
                <p>【保证最终一致性】</p>
                <p>第三种方式就是业务不依赖数据同步的实时性，只要数据最终能一致即可。例如：A机房注册了一个用户，业务上不要求能够在50ms内就同步到所有机房，正常情况下要求5分钟同步到所有机房即可，异常情况下甚至可以允许1小时或者1天后能够一致。</p>
                <p> 最终一致性在具体实现的时候，还需要根据不同的数据特征，进行差异化的处理，以满足业务需要。例如对“账号”信息来说，如果在A机房新注册的用户5分钟内正好跑到B机房了，此时B机房还没有这个用户的信息，为了保证业务的正确，B机房就需要根据路由规则到A机房请求数据（这种处理方式其实就是后面讲的“<strong>二次读取</strong>”）。</p>
                <p>而对“用户信息”来说，5分钟后同步也没有问题，也不需要采取其它措施来弥补，但还是会影响用户体验，即用户看到了旧的用户信息，这个问题怎么解决呢？这个问题实际上也涉及到了一个思维误区，在最后我们统一分析。 </p>
                <p>&nbsp;</p>
                <p>只使用存储系统的同步功能</p>
                <p>数据同步是异地多活方案设计的核心，幸运的是基本上存储系统本身都会有同步的功能，例如MySQL的主备复制、Redis的Cluster功能、elasticsearch的集群功能。这些系统本身的同步功能已经比较强大，能够直接拿来就用，但这也无形中将我们引入了一个思维误区：只使用存储系统的同步功能！</p>
                <p> 既然说存储系统本身就有同步功能，而且同步功能还很强大，为何说只使用存储系统是一个思维误区呢？因为虽然绝大部分场景下，存储系统本身的同步功能基本上也够用了，但在某些比较极端的情况下，存储系统本身的同步功能可能难以满足业务需求。</p>
                <p> 以MySQL为例，MySQL5.1版本的复制是单线程的复制，在网络抖动或者大量数据同步的时候，经常发生延迟较长的问题，短则延迟十几秒，长则可能达到十几分钟。而且即使我们通过监控的手段知道了MySQL同步时延较长，也难以采取什么措施，只能干等。</p>
                <p> Redis又是另外一个问题，Redis 3.0之前没有Cluster功能，只有主从复制功能，而为了设计上的简单，Redis主从复制有一个比较大的隐患：从机宕机或者和主机断开连接都需要重新连接主机，重新连接主机都会触发全量的主从复制，这时候主机会生成内存快照，主机依然可以对外提供服务，但是作为读的从机，就无法提供对外服务了，如果数据量大，恢复的时间会相当的长。</p>
                <p>综合上述的案例可以看出，<strong>存储系统本身自带的同步功能，在某些场景下是无法满足我们业务需要的。</strong>尤其是异地多机房这种部署，各种各样的异常都可能出现，当我们只考虑存储系统本身的同步功能时，就会发现无法做到真正的异地多活。</p>
                <p> 解决的方案就是拓开思路，避免只使用存储系统的同步功能，可以将多种手段配合存储系统的同步来使用，甚至可以不采用存储系统的同步方案，改用自己的同步方案。</p>
                <p> 例如，还是以前面的“用户子系统”为例，我们可以采用如下几种方式同步数据：</p>
                <ol>
                    <li>消息队列方式：对于账号数据，由于账号只会创建，不会修改和删除（假设我们不提供删除功能），我们可以将账号数据通过消息队列同步到其它业务中心。</li>
                    <li>二次读取方式：某些情况下可能出现消息队列同步也延迟了，用户在A中心注册，然后访问B中心的业务，此时B中心本地拿不到用户的账号数据。为了解决这个问题，B中心在读取本地数据失败的时候，可以根据路由规则，再去A中心访问一次（这就是所谓的二次读取，第一次读取本地，本地失败后第二次读取对端），这样就能够解决异常情况下同步延迟的问题。</li>
                    <li>存储系统同步方式：对于密码数据，由于用户改密码频率较低，而且用户不可能在1s内连续改多次密码，所以通过数据库的同步机制将数据复制到其它业务中心即可，用户信息数据和密码类似。</li>
                    <li>回源读取方式：对于登录的session数据，由于数据量很大，我们可以不同步数据；但当用户在A中心登录后，然后又在B中心登录，B中心拿到用户上传的session id后，根据路由判断session属于A中心，直接去A中心请求session数据即可，反之亦然，A中心也可以到B中心去拿取session数据。</li>
                    <li>重新生成数据方式：对于第4中场景，如果异常情况下，A中心宕机了，B中心请求session数据失败，此时就只能登录失败，让用户重新在B中心登录，生成新的session数据。</li>

                </ol>
                <p>（注意：以上方案仅仅是示意，实际的设计方案要比这个复杂一些，还有很多细节要考虑）</p>
                <p>&nbsp;</p>
                <p>100%可用性</p>
                <p>前面我们在给出每个思维误区对应的解决方案的时候，其实都遗留了一些小尾巴：某些场景下我们无法保证100%的业务可用性，总是会有一定的损失。例如密码不同步导致无法登录、用户信息不同步导致用户看到旧的用户信息等等，这个问题怎么解决？</p>
                <p>其实这个问题涉及异地多活设计方案中一个典型的思维误区：我要保证业务100%可用！但极端情况下就是会丢一部分数据，就是会有一部分数据不能同步，怎么办呢，有没有什么巧妙和神通的办法能做到？</p>
                <p>很遗憾，答案是没有！异地多活也无法保证100%的业务可用，这是由物理规律决定的，光速和网络的传播速度、硬盘的读写速度、极端异常情况的不可控等，都是无法100%解决的。所以针对这个思维误区，我的答案是“忍”！也就是说我们要忍受这一小部分用户或者业务上的损失，否则本来想为了保证最后的0.01%的用户的可用性，做个完美方案，结果却发现99.99%的用户都保证不了了。</p>
                <p>对于某些实时强一致性的业务，实际上受影响的用户会更多，甚至可能达到1/3的用户。以银行转账这个业务为例，假设小明在北京XX银行开了账号，如果小明要转账，一定要北京的银行业务中心是可用的，否则就不允许小明自己转账。</p>
                <p>如果不这样的话，假设在北京和上海两个业务中心实现了实时转账的异地多活，某些异常情况下就可能出现小明只有1万存款，他在北京转给了张三1万，然后又到上海转给了李四1万，两次转账都成功了。这种漏洞如果被人利用，后果不堪设想。</p>
                <p>当然，针对银行转账这个业务，可以有很多特殊的业务手段来实现异地多活。例如分为“实时转账”和“转账申请”。</p>
                <p>实时转账就是我们上述的案例，是无法做到“异地多活”的；但“转账申请”是可以做到“异地多活”的，即：小明在上海业务中心提交转账请求，但上海的业务中心并不立即转账，而是记录这个转账请求，然后后台异步发起真正的转账操作，如果此时北京业务中心不可用，转账请求就可以继续等待重试；假设等待2个小时后北京业务中心恢复了，此时上海业务中心去请求转账，发现余额不够，这个转账请求就失败了。</p>
                <p>小明再登录上来就会看到转账申请失败，原因是“余额不足”。不过需要注意的是“转账申请”的这种方式虽然有助于实现异地多活，但其实还是牺牲了用户体验的，对于小明来说，本来一次操作的事情，需要分为两次：一次提交转账申请，另外一次要确认是否转账成功。</p>
                <p>虽然我们无法做到100%可用性，但并不意味着我们什么都不能做，为了让用户心里更好受一些，我们可以采取一些措施进行安抚或者补偿，例如：</p>
                <ol>
                    <li>挂公告：说明现在有问题和基本的问题原因，如果不明确原因或者不方便说出原因，可以说“技术哥哥正在紧急处理”比较轻松和有趣的公告。</li>
                    <li>事后对用户进行补偿：例如送一些业务上可用的代金券、小礼包等，降低用户的抱怨。</li>
                    <li>补充体验：对于为了做异地多活而带来的体验损失，可以想一些方法减少或者规避。以“转账申请”为例，为了让用户不用确认转账申请是否成功，我们可以在转账成功或者失败后直接给用户发个短信，告诉他转账结果，这样用户就不用不时的登录系统来确认转账是否成功了。</li>

                </ol>
                <p>综合前面的分析，异地多活设计的理念可以总结为一句话：采用多种手段，保证绝大部分用户的核心业务异地多活！</p>
                <hr />
                <p>做过数据备份的各位一定知道CAP理论。2000年加州伯克利大学认为分布式系统有一致性，所有节点在任何时间都可以访问到最新的数据副本；每个请求都能收到一个响应，无论是成功还是失败，必须有服务器的响应，而不是TCP超时、TCP断开等；其中一个区挂了，不影响其他分区。</p>
                <p>这三个特性无法共存，只能取两点，牺牲另一点。</p>
                <p>AC模型，可用性+强一致性，牺牲了分区容忍性。比如MySQL Cluster集群，内部还是可以用的，MySQL集群提供两阶段提交事务方式，保证各节点数据强一致性。MySQL的集群无法忍受脱离集群独立工作，一旦和集群脱离了心跳，节点出问题，导致分布式事务操作到那个节点后，整个就会失败，这是MySQL的牺牲。</p>
                <p>CP模型，一致性+分区容忍，牺牲了可用性。Redis客户端Hash和Twemproxy集群，各Redis节点无共享数据，所以不存在节点间的数据不一致问题。其中节点大了，都会影响整个Redis集群的工作。当Redis某节点失效后，这个节点里的所有数据都无法访问。如果使用3.0 Redis Cluster，它有中心管理节点负责做数据路由。</p>
                <p>AP模型，可用性+分区容忍性，牺牲了强一致性。用Cassandra集群时，数据可以访问，数据能备份到各个节点之间，其中一个节点失效的话，数据还是可以出来的。而分布式事务的各个节点更新了提交了只是其中一部分节点，底层继续同步，这是AP模型。</p>
                <p>&nbsp;</p>
                <p>不同的业务类型要求不同的CAP模型，CA适用于支付、交易、票务等强一致性的行业，宁愿业务不可用，也不能容忍脏数据。互联网业务对于强一致性不高，发个帖子要审核，没人看到无所谓。发一个音频要进行编码审核才能看到。</p>
                <p>&nbsp;</p>
                <p>Base模型是什么？eBay工程师提出大规模分布式系统的实践总结，在ACM上发表文章提出 Bash 理论是基本可用、软状态和最终一致性。不要求实时一致性，但一定要实现最后一点。</p>
                <p><strong>基本可用（Basically Available）。</strong>分布式系统在故障时允许损失可用性，保证核心业务可用。音频直播或是做活动时，当业务量非常大的时候可以降级。做游戏也是，在战斗的时候最关心数值的增长，看了多少人都无所谓，缓解核心内容的压力。</p>
                <p><strong>软状态（Soft State）。</strong>允许系统中出现的中间状态，中间状态不会耽误可用性。在写代码、编程业务的设计上，必须容忍有一定的临时数据同步，考虑到全局锁和数据多版本的对比，把各个节点的相关数据都上锁，这是一个悲观锁，一旦写任务，其他人都能改我的数据，这是比较悲观的心态。</p>
                <p>而数据多版本，类似于乐观锁，导致其他人和我方数据冲突的机会并不是那么多，只要在提交的时候发现版本不一样，更新一下，汇总数据就可以了。做好业务上的隔 离，多数情况都属于多版本，技术都能解决，不一定要把所有的东西都锁死。允许有一定的临时数据。最终一致性，在临时上的数据不一样，数据同步也是要花时间 的。</p>
                <p>随着时间的迁移，不同节点的数据总是向同一个方向有一个相同的变化，这是Base模型。这种模型非常适合互联网业务的发展。</p>
                <p>数据一致性模型。允许窗口期数据不一致，互相关联的数据要同步。序列一致性，全局按照序列顺序来做。线性一致性，每一个时间的时钟要同步，时间序列是严格的，按顺序的。最后是强一致性，一个时间只能实行一个任务。 </p>
                <hr />
                <p>业务多活：广州地区的朋友在淘宝上购物，在广州的服务器上完成所有操作，广州与其他数据中心进行同步。要是广州的服务宕机了，分流到重庆中心。</p>
                <p>业务多活V用户分区,用户分区一般是按照dns分区的，也有可能按照注册地分区</p>
                <p>根据业务类型来判断是否可以使用业务多活，如果不能使用业务多活，可以通过什么手段来近似实现业务多活的功能？</p>
                <p>&nbsp;</p>
            </div>
        );
    }
}

export default IDC;